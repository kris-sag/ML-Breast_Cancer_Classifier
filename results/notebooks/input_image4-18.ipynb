{"cells":[{"cell_type":"code","execution_count":1,"source":["from __future__ import print_function, division\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","from PIL import Image\n","\n","\n","#repo_dir = 'C:\\\\Users\\MP_lab_GPU\\Desktop\\Senior Design 2019\\Senior Design\\'\n","\n","# CHANGE THIS DIRECTORY TO THE ML BREAST CANCER TOTAL FILES FOLDER\n","# repo_dir = r'C:\\Users\\joekh\\Documents\\GitHub\\ML-Breat_Cancer_Classfier\\\\'\n","reop_dir = r'C:\\Users\\Kris\\..vs code files\\senior design\\ML-Breat_Cancer_Classfier-master'"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":2,"source":["imsize = 256\n","loader = transforms.Compose([\n","            transforms.RandomResizedCrop(224),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.ToTensor(),\n","            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","        ])\n","\n","#\n","def image_loader(loader, image_name):\n","    image = Image.open(image_name)\n","    image = loader(image).float()\n","    image = torch.tensor(image, requires_grad=True)\n","    image = image.unsqueeze(0)\n","    return image\n","\n","# model = models.resnet152(pretrained=True)\n","# num_ftrs = model.fc.in_features\n","# model.fc = nn.Linear(num_ftrs, 2)\n","\n","model = models.vgg16(pretrained=True)\n","num_ftrs = model.classifier[0].in_features\n","model.classifier = nn.Linear(num_ftrs, 2)\n","\n","\n","#CHANGE PATH TO MODEL PATH, CHANGE MAP LOCATION BASED ON GPU\n","model.load_state_dict(torch.load(r'C:\\Users\\Kris\\..vs code files\\senior design\\ML-Breat_Cancer_Classfier-master\\model\\\\4-18_vgg_model_state_dict.pt',\n","                                 map_location=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")), strict=False)\n","model.eval()\n","#CHANGE PATH LOCATION TO FOLDER WITH CROPPED MALIGNANT IMAGES\n","malignant_path = r'C:\\Users\\Kris\\..vs code files\\senior design\\ML-Breat_Cancer_Classfier-master\\images\\Photos for Testing\\data_test\\Cancer'\n","#CHANGE PATH LOCATION TO FOLDER WITH CROPPED NONMALIGNANT IMAGES\n","non_malignant_path = r'C:\\Users\\Kris\\..vs code files\\senior design\\ML-Breat_Cancer_Classfier-master\\images\\Photos for Testing\\data_test\\Not_Cancer'"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["#### THE FIRST ARGUMENT IS BENIGN, SECOND IS MALIGNANT\n","tp = [] #num correctly diagnosed malignant\n","fp = [] #num incorrectly diagnosed malignant\n","tn = [] #num correctly diagnosed benign\n","fn = [] #num incorrectly diagnosed negative\n","errors = 0\n","num_malignant = 0\n","num_non_malignant = 0\n","\n","for i in os.listdir(malignant_path):\n","    try:\n","        image = image_loader(loader, os.path.join(malignant_path, i))\n","        \n","        y = model(image)\n","        if y.argmax().item() == 0:\n","            fn.append(i)\n","        else:\n","            tp.append(i)\n","        num_malignant +=1\n","    except:\n","        print(i)\n","        errors +=1\n","        \n","for i in os.listdir(non_malignant_path):\n","    try:\n","        image = image_loader(loader, os.path.join(non_malignant_path, i))\n","        num_non_malignant +=1\n","        y = model(image)\n","        if y.argmax().item() == 0:\n","            tn.append(i)\n","        else:\n","            fp.append(i)\n","    except:\n","        errors +=1\n","\n","print(\"True Positives: \" + str(len(tp)))\n","print(\"True Negatives: \"+ str(len(tn)))\n","print(\"False Positives: \"+ str(len(fp)))\n","print(\"False Negatives: \"+ str(len(fn)))\n","print(\"Total Number of images: \"+ str((len(tp)+len(tn)+len(fp)+len(fn))))"],"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-2-201b72758311>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  image = torch.tensor(image, requires_grad=True)\n"]},{"output_type":"stream","name":"stdout","text":["True Positives: 352\n","True Negatives: 260\n","False Positives: 95\n","False Negatives: 522\n","Total Number of images: 1229\n"]}],"metadata":{}}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}